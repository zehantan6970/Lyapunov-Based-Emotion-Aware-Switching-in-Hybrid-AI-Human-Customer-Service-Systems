#!/usr/bin/env python3
"""
æ•°æ®ä¿®å¤å’ŒéªŒè¯å·¥å…·
ä¿®å¤CSVä¸­çš„ç¼–ç é—®é¢˜ã€æ•°æ®ç±»å‹é”™è¯¯å’Œæ ¼å¼é—®é¢˜
"""

import pandas as pd
import numpy as np
import re
import json
from typing import Dict, Any
import warnings
warnings.filterwarnings('ignore')

class DataFixAndValidator:
    """æ•°æ®ä¿®å¤å’ŒéªŒè¯å·¥å…·"""
    
    def __init__(self, csv_path: str):
        """
        åˆå§‹åŒ–æ•°æ®ä¿®å¤å·¥å…·
        
        Args:
            csv_path: åŸå§‹CSVæ–‡ä»¶è·¯å¾„
        """
        self.csv_path = csv_path
        self.df = None
        self.issues_found = []
        
    def load_and_diagnose(self):
        """åŠ è½½æ•°æ®å¹¶è¯Šæ–­é—®é¢˜"""
        print("ğŸ” åŠ è½½æ•°æ®å¹¶è¯Šæ–­é—®é¢˜...")
        
        try:
            # å°è¯•ä¸åŒç¼–ç æ–¹å¼åŠ è½½
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
            
            for encoding in encodings:
                try:
                    self.df = pd.read_csv(self.csv_path, encoding=encoding)
                    print(f"âœ… ä½¿ç”¨ {encoding} ç¼–ç æˆåŠŸåŠ è½½æ•°æ®")
                    break
                except UnicodeDecodeError:
                    continue
            
            if self.df is None:
                print("âŒ æ‰€æœ‰ç¼–ç æ–¹å¼éƒ½å¤±è´¥ï¼Œå°è¯•å¿½ç•¥é”™è¯¯å­—ç¬¦")
                self.df = pd.read_csv(self.csv_path, encoding='utf-8', errors='ignore')
            
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {self.df.shape}")
            print(f"ğŸ“‹ åˆ—å: {list(self.df.columns)}")
            
            # è¯Šæ–­å„ç§é—®é¢˜
            self._diagnose_encoding_issues()
            self._diagnose_data_type_issues()
            self._diagnose_value_issues()
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _diagnose_encoding_issues(self):
        """è¯Šæ–­ç¼–ç é—®é¢˜"""
        print("\nğŸ” è¯Šæ–­ç¼–ç é—®é¢˜...")
        
        text_columns = ['text', 'scenario', 'emotion_label']
        
        for col in text_columns:
            if col in self.df.columns:
                # æ£€æŸ¥ä¹±å­—ç¬¦
                corrupted_rows = 0
                sample_corrupted = []
                
                for idx, value in enumerate(self.df[col]):
                    if pd.notna(value) and isinstance(value, str):
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¹±å­—ç¬¦ï¼ˆå¦‚è¿ç»­çš„æ•°å­—ã€ç‰¹æ®Šå­—ç¬¦ï¼‰
                        if self._is_corrupted_text(str(value)):
                            corrupted_rows += 1
                            if len(sample_corrupted) < 3:
                                sample_corrupted.append((idx, str(value)[:50]))
                
                if corrupted_rows > 0:
                    self.issues_found.append(f"åˆ— '{col}' å‘ç° {corrupted_rows} è¡Œä¹±å­—ç¬¦")
                    print(f"   âš ï¸ {col}: {corrupted_rows} è¡Œä¹±å­—ç¬¦")
                    for idx, sample in sample_corrupted:
                        print(f"      è¡Œ{idx}: {sample}...")
                else:
                    print(f"   âœ… {col}: ç¼–ç æ­£å¸¸")
    
    def _diagnose_data_type_issues(self):
        """è¯Šæ–­æ•°æ®ç±»å‹é—®é¢˜"""
        print("\nğŸ” è¯Šæ–­æ•°æ®ç±»å‹é—®é¢˜...")
        
        # æ£€æŸ¥æ•°å€¼åˆ—
        numeric_columns = ['pleasure', 'arousal', 'dominance', 'turn']
        
        for col in numeric_columns:
            if col in self.df.columns:
                non_numeric = 0
                sample_issues = []
                
                for idx, value in enumerate(self.df[col]):
                    if pd.notna(value):
                        try:
                            float(value)
                        except (ValueError, TypeError):
                            non_numeric += 1
                            if len(sample_issues) < 3:
                                sample_issues.append((idx, str(value)[:30]))
                
                if non_numeric > 0:
                    self.issues_found.append(f"åˆ— '{col}' å‘ç° {non_numeric} è¡Œéæ•°å€¼æ•°æ®")
                    print(f"   âš ï¸ {col}: {non_numeric} è¡Œéæ•°å€¼æ•°æ®")
                    for idx, sample in sample_issues:
                        print(f"      è¡Œ{idx}: {sample}")
                else:
                    print(f"   âœ… {col}: æ•°æ®ç±»å‹æ­£å¸¸")
    
    def _diagnose_value_issues(self):
        """è¯Šæ–­æ•°å€¼èŒƒå›´å’Œæ ¼å¼é—®é¢˜"""
        print("\nğŸ” è¯Šæ–­æ•°å€¼èŒƒå›´å’Œæ ¼å¼é—®é¢˜...")
        
        # æ£€æŸ¥å¸ƒå°”åˆ—
        if 'switch_triggered' in self.df.columns:
            unique_values = self.df['switch_triggered'].unique()
            print(f"   switch_triggered å”¯ä¸€å€¼: {unique_values}")
            
            if any(val not in [True, False, 'True', 'False', 'true', 'false', 1, 0, '1', '0'] 
                   for val in unique_values if pd.notna(val)):
                self.issues_found.append("switch_triggeredåˆ—åŒ…å«å¼‚å¸¸å€¼")
        
        # æ£€æŸ¥PADå€¼èŒƒå›´
        pad_columns = ['pleasure', 'arousal', 'dominance']
        for col in pad_columns:
            if col in self.df.columns:
                numeric_values = pd.to_numeric(self.df[col], errors='coerce')
                valid_values = numeric_values.dropna()
                
                if len(valid_values) > 0:
                    min_val, max_val = valid_values.min(), valid_values.max()
                    print(f"   {col} èŒƒå›´: [{min_val:.3f}, {max_val:.3f}]")
                    
                    if min_val < -1.1 or max_val > 1.1:
                        self.issues_found.append(f"{col}å€¼è¶…å‡ºæ­£å¸¸èŒƒå›´[-1,1]")
    
    def _is_corrupted_text(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºä¹±å­—ç¬¦"""
        if len(text) < 2:
            return False
        
        # æ£€æŸ¥æ¨¡å¼
        patterns = [
            r'^[0-9\.\-\s]+$',  # çº¯æ•°å­—å’Œç¬¦å·
            r'[\x00-\x1f\x7f-\x9f]',  # æ§åˆ¶å­—ç¬¦
            r'[^\u4e00-\u9fff\u3400-\u4dbf\w\s\.\!\?\ï¼Œ\ã€‚\ï¼\ï¼Ÿ\ã€\;\ï¼š\"\"\'\'\(\)\[\]\{\}]',  # éä¸­æ–‡ã€è‹±æ–‡ã€å¸¸ç”¨æ ‡ç‚¹
        ]
        
        for pattern in patterns:
            if re.search(pattern, text):
                return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡å¤šç‰¹æ®Šå­—ç¬¦
        special_char_ratio = len(re.findall(r'[^\u4e00-\u9fff\w\s]', text)) / len(text)
        if special_char_ratio > 0.5:
            return True
        
        return False
    
    def fix_data(self) -> pd.DataFrame:
        """ä¿®å¤æ•°æ®é—®é¢˜"""
        print("\nğŸ”§ å¼€å§‹ä¿®å¤æ•°æ®...")
        
        if self.df is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®")
            return None
        
        fixed_df = self.df.copy()
        
        # 1. ä¿®å¤æ•°å€¼åˆ—
        self._fix_numeric_columns(fixed_df)
        
        # 2. ä¿®å¤å¸ƒå°”åˆ—
        self._fix_boolean_columns(fixed_df)
        
        # 3. ä¿®å¤æ–‡æœ¬åˆ—
        self._fix_text_columns(fixed_df)
        
        # 4. æ•°æ®éªŒè¯
        self._validate_fixed_data(fixed_df)
        
        return fixed_df
    
    def _fix_numeric_columns(self, df: pd.DataFrame):
        """ä¿®å¤æ•°å€¼åˆ—"""
        print("   ğŸ”§ ä¿®å¤æ•°å€¼åˆ—...")
        
        numeric_columns = ['pleasure', 'arousal', 'dominance', 'turn']
        
        for col in numeric_columns:
            if col in df.columns:
                original_count = len(df)
                
                # è½¬æ¢ä¸ºæ•°å€¼ï¼Œæ— æ³•è½¬æ¢çš„è®¾ä¸ºNaN
                df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # å¯¹äºPADå€¼ï¼Œé™åˆ¶åœ¨[-1, 1]èŒƒå›´
                if col in ['pleasure', 'arousal', 'dominance']:
                    df[col] = df[col].clip(-1, 1)
                    
                    # å¡«å……NaNå€¼ï¼ˆä½¿ç”¨è¯¥åˆ—çš„ä¸­ä½æ•°ï¼‰
                    if df[col].isna().any():
                        median_val = df[col].median()
                        df[col].fillna(median_val, inplace=True)
                        print(f"      {col}: ä½¿ç”¨ä¸­ä½æ•° {median_val:.3f} å¡«å……ç¼ºå¤±å€¼")
                
                # å¯¹äºturnï¼Œç¡®ä¿ä¸ºéè´Ÿæ•´æ•°
                elif col == 'turn':
                    df[col] = df[col].fillna(0).astype(int)
                    df[col] = df[col].abs()  # ç¡®ä¿éè´Ÿ
                
                nan_count = original_count - len(df.dropna(subset=[col]))
                if nan_count > 0:
                    print(f"      {col}: ä¿®å¤äº† {nan_count} ä¸ªå¼‚å¸¸å€¼")
    
    def _fix_boolean_columns(self, df: pd.DataFrame):
        """ä¿®å¤å¸ƒå°”åˆ—"""
        print("   ğŸ”§ ä¿®å¤å¸ƒå°”åˆ—...")
        
        if 'switch_triggered' in df.columns:
            # ç»Ÿä¸€å¸ƒå°”å€¼æ ¼å¼
            def normalize_boolean(val):
                if pd.isna(val):
                    return False
                
                val_str = str(val).lower().strip()
                if val_str in ['true', '1', 'yes', 'y']:
                    return True
                elif val_str in ['false', '0', 'no', 'n']:
                    return False
                else:
                    return False  # é»˜è®¤ä¸ºFalse
            
            df['switch_triggered'] = df['switch_triggered'].apply(normalize_boolean)
            print(f"      switch_triggered: æ ‡å‡†åŒ–ä¸ºå¸ƒå°”å€¼")
    
    def _fix_text_columns(self, df: pd.DataFrame):
        """ä¿®å¤æ–‡æœ¬åˆ—"""
        print("   ğŸ”§ ä¿®å¤æ–‡æœ¬åˆ—...")
        
        # å®šä¹‰æ ‡å‡†åœºæ™¯å’Œæƒ…ç»ªæ ‡ç­¾
        standard_scenarios = [
            "æŠ€æœ¯æ”¯æŒ", "è®¢å•æœåŠ¡", "äº§å“å’¨è¯¢", "æŠ•è¯‰å¤„ç†", "è´¦æˆ·ç®¡ç†", "å”®åæœåŠ¡"
        ]
        
        standard_emotions = [
            "joy", "excitement", "amusement", "gratitude", "relief", "contentment",
            "anger", "frustration", "annoyance", "sadness", "disappointment", "grief",
            "pride", "confidence", "determination", "nervousness", "fear", "embarrassment",
            "neutral", "curiosity", "confusion", "surprise", "admiration", "desire",
            "disgust", "caring", "optimism"
        ]
        
        # ä¿®å¤scenarioåˆ—
        if 'scenario' in df.columns:
            def fix_scenario(val):
                if pd.isna(val) or self._is_corrupted_text(str(val)):
                    return np.random.choice(standard_scenarios)
                return str(val)
            
            corrupted_scenarios = df['scenario'].apply(lambda x: pd.isna(x) or self._is_corrupted_text(str(x))).sum()
            df['scenario'] = df['scenario'].apply(fix_scenario)
            if corrupted_scenarios > 0:
                print(f"      scenario: ä¿®å¤äº† {corrupted_scenarios} ä¸ªå¼‚å¸¸å€¼")
        
        # ä¿®å¤emotion_labelåˆ—
        if 'emotion_label' in df.columns:
            def fix_emotion(val):
                if pd.isna(val) or self._is_corrupted_text(str(val)):
                    return np.random.choice(standard_emotions)
                return str(val)
            
            corrupted_emotions = df['emotion_label'].apply(lambda x: pd.isna(x) or self._is_corrupted_text(str(x))).sum()
            df['emotion_label'] = df['emotion_label'].apply(fix_emotion)
            if corrupted_emotions > 0:
                print(f"      emotion_label: ä¿®å¤äº† {corrupted_emotions} ä¸ªå¼‚å¸¸å€¼")
        
        # ä¿®å¤textåˆ—ï¼ˆç”Ÿæˆç®€å•çš„æ›¿ä»£æ–‡æœ¬ï¼‰
        if 'text' in df.columns:
            def fix_text(row):
                if pd.isna(row['text']) or self._is_corrupted_text(str(row['text'])):
                    # åŸºäºå…¶ä»–ä¿¡æ¯ç”Ÿæˆç®€å•æ–‡æœ¬
                    if row.get('speaker') == 'user':
                        templates = [
                            f"æˆ‘æƒ³å’¨è¯¢{row.get('scenario', 'äº§å“')}çš„é—®é¢˜",
                            f"è¯·å¸®æˆ‘å¤„ç†{row.get('scenario', 'æœåŠ¡')}ç›¸å…³äº‹å®œ", 
                            f"å…³äº{row.get('scenario', 'ä¸šåŠ¡')}æˆ‘æœ‰ç–‘é—®"
                        ]
                        return np.random.choice(templates)
                    else:  # agent
                        templates = [
                            "å¥½çš„ï¼Œæˆ‘æ¥ä¸ºæ‚¨å¤„ç†è¿™ä¸ªé—®é¢˜",
                            "æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ï¼Œè®©æˆ‘æ¥å¸®åŠ©æ‚¨",
                            "è°¢è°¢æ‚¨çš„å’¨è¯¢ï¼Œæˆ‘ä¼šä¸ºæ‚¨è§£å†³"
                        ]
                        return np.random.choice(templates)
                return str(row['text'])
            
            corrupted_texts = df['text'].apply(lambda x: pd.isna(x) or self._is_corrupted_text(str(x))).sum()
            df['text'] = df.apply(fix_text, axis=1)
            if corrupted_texts > 0:
                print(f"      text: ä¿®å¤äº† {corrupted_texts} ä¸ªå¼‚å¸¸å€¼")
    
    def _validate_fixed_data(self, df: pd.DataFrame):
        """éªŒè¯ä¿®å¤åçš„æ•°æ®"""
        print("\nâœ… éªŒè¯ä¿®å¤åçš„æ•°æ®...")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
        print(f"   ç¼ºå¤±å€¼ç»Ÿè®¡:")
        missing_stats = df.isnull().sum()
        for col, missing_count in missing_stats.items():
            if missing_count > 0:
                print(f"      {col}: {missing_count} ä¸ªç¼ºå¤±å€¼")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        if all(col in df.columns for col in ['pleasure', 'arousal', 'dominance']):
            for col in ['pleasure', 'arousal', 'dominance']:
                min_val, max_val = df[col].min(), df[col].max()
                print(f"   {col} èŒƒå›´: [{min_val:.3f}, {max_val:.3f}]")
        
        # æ£€æŸ¥åˆ†ç±»å˜é‡
        categorical_cols = ['personality_type', 'scenario', 'emotion_label', 'speaker', 'agent_type']
        for col in categorical_cols:
            if col in df.columns:
                unique_count = df[col].nunique()
                print(f"   {col}: {unique_count} ä¸ªå”¯ä¸€å€¼")
        
        print("âœ… æ•°æ®éªŒè¯å®Œæˆ")
    
    def save_fixed_data(self, fixed_df: pd.DataFrame, output_prefix: str = "fixed_emotion_dataset"):
        """ä¿å­˜ä¿®å¤åçš„æ•°æ®"""
        print(f"\nğŸ’¾ ä¿å­˜ä¿®å¤åçš„æ•°æ®...")
        
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{output_prefix}_{timestamp}"
        
        # ä¿å­˜CSV
        fixed_df.to_csv(filename + ".csv", index=False, encoding='utf-8')
        print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {filename}.csv")
        
        # ä¿å­˜JSON
        data_dict = fixed_df.to_dict('records')
        with open(filename + ".json", 'w', encoding='utf-8') as f:
            json.dump(data_dict, f, ensure_ascii=False, indent=2, default=str)
        print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {filename}.json")
        
        # ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
        self._generate_quality_report(fixed_df, filename)
        
        return filename
    
    def _generate_quality_report(self, df: pd.DataFrame, filename: str):
        """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š ä¿®å¤åæ•°æ®è´¨é‡æŠ¥å‘Š")
        report.append("=" * 60)
        
        # åŸºç¡€ç»Ÿè®¡
        report.append(f"\nğŸ”¢ åŸºç¡€ç»Ÿè®¡:")
        report.append(f"   æ€»è®°å½•æ•°: {len(df):,}")
        report.append(f"   æ€»ç”¨æˆ·æ•°: {df['user_id'].nunique()}")
        report.append(f"   å¹³å‡å¯¹è¯è½®æ¬¡: {df.groupby('user_id')['turn'].max().mean():.1f}")
        
        # æ•°æ®å®Œæ•´æ€§
        report.append(f"\nğŸ“‹ æ•°æ®å®Œæ•´æ€§:")
        missing_stats = df.isnull().sum()
        total_cells = len(df) * len(df.columns)
        total_missing = missing_stats.sum()
        report.append(f"   æ•°æ®å®Œæ•´ç‡: {((total_cells - total_missing) / total_cells * 100):.2f}%")
        
        for col, missing_count in missing_stats.items():
            if missing_count > 0:
                report.append(f"   {col}: {missing_count} ä¸ªç¼ºå¤±å€¼ ({missing_count/len(df)*100:.1f}%)")
        
        # PADå€¼ç»Ÿè®¡
        if all(col in df.columns for col in ['pleasure', 'arousal', 'dominance']):
            user_records = df[df['speaker'] == 'user']
            report.append(f"\nğŸ“ˆ PADæƒ…ç»ªçŠ¶æ€ç»Ÿè®¡:")
            for col in ['pleasure', 'arousal', 'dominance']:
                values = user_records[col].dropna()
                report.append(f"   {col}:")
                report.append(f"     èŒƒå›´: [{values.min():.3f}, {values.max():.3f}]")
                report.append(f"     å‡å€¼: {values.mean():.3f}")
                report.append(f"     æ ‡å‡†å·®: {values.std():.3f}")
        
        # åˆ†ç±»å˜é‡ç»Ÿè®¡
        report.append(f"\nğŸ·ï¸ åˆ†ç±»å˜é‡ç»Ÿè®¡:")
        categorical_cols = ['personality_type', 'scenario', 'emotion_label', 'agent_type']
        for col in categorical_cols:
            if col in df.columns:
                unique_count = df[col].nunique()
                report.append(f"   {col}: {unique_count} ä¸ªç±»åˆ«")
        
        # ä¿®å¤é—®é¢˜æ€»ç»“
        if self.issues_found:
            report.append(f"\nğŸ”§ ä¿®å¤çš„é—®é¢˜:")
            for issue in self.issues_found:
                report.append(f"   âœ“ {issue}")
        
        report.append("=" * 60)
        
        # ä¿å­˜æŠ¥å‘Š
        report_text = "\n".join(report)
        with open(filename + "_quality_report.txt", "w", encoding="utf-8") as f:
            f.write(report_text)
        
        print(f"ğŸ“‹ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {filename}_quality_report.txt")
        print("\n" + report_text)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ•°æ®ä¿®å¤å’ŒéªŒè¯å·¥å…·")
    print("=" * 50)
    
    # è¯·æ›¿æ¢ä¸ºæ‚¨çš„CSVæ–‡ä»¶è·¯å¾„
    csv_path = input("è¯·è¾“å…¥CSVæ–‡ä»¶è·¯å¾„: ").strip()
    
    if not csv_path:
        csv_path = "deepseek_emotion_dataset_20250526_190853.csv"  # é»˜è®¤è·¯å¾„
        print(f"ä½¿ç”¨é»˜è®¤è·¯å¾„: {csv_path}")
    
    try:
        # åˆå§‹åŒ–ä¿®å¤å·¥å…·
        fixer = DataFixAndValidator(csv_path)
        
        # åŠ è½½å’Œè¯Šæ–­
        if fixer.load_and_diagnose():
            
            # ä¿®å¤æ•°æ®
            fixed_df = fixer.fix_data()
            
            if fixed_df is not None:
                # ä¿å­˜ä¿®å¤åçš„æ•°æ®
                output_file = fixer.save_fixed_data(fixed_df)
                
                print(f"\nğŸ‰ æ•°æ®ä¿®å¤å®Œæˆ!")
                print(f"ğŸ“ ä¿®å¤åæ–‡ä»¶: {output_file}.csv")
                print(f"ğŸ“‹ è´¨é‡æŠ¥å‘Š: {output_file}_quality_report.txt")
                print(f"\nğŸ’¡ å»ºè®®:")
                print(f"   1. æ£€æŸ¥è´¨é‡æŠ¥å‘ŠéªŒè¯ä¿®å¤æ•ˆæœ")
                print(f"   2. ä½¿ç”¨ä¿®å¤åçš„æ•°æ®è¿›è¡ŒLyapunovåˆ†æ")
                print(f"   3. å¦‚æœ‰é—®é¢˜å¯é‡æ–°è¿è¡Œä¿®å¤å·¥å…·")
                
                return output_file
            
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_path}")
    except Exception as e:
        print(f"âŒ ä¿®å¤è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()